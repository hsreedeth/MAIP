{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acc01bd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# build_app_data.py\n",
    "import json\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.manifold import SpectralEmbedding  # or UMAP if you prefer\n",
    "\n",
    "# =========================\n",
    "# 0. CONFIG – EDIT THESE\n",
    "# =========================\n",
    "\n",
    "OUTPUT_JSON = Path(\"snf-data.json\")\n",
    "\n",
    "# TODO: point these to your actual objects / files\n",
    "\n",
    "# 1) Patient index & metadata\n",
    "#    meta must have index = patient_id, columns: \"age\", \"sex\" (0/1 or 'M'/'F'), and some risk variable.\n",
    "def load_meta() -> pd.DataFrame:\n",
    "    # Example: from a CSV you already use\n",
    "    meta = pd.read_csv(\"/Users/harisreedeth/Desktop/D/personal/ProjectMAIP/data/01_processed/support_preprocessed_clean.csv\").set_index(\"eid\")\n",
    "    return meta\n",
    "\n",
    "# 2) View matrices (C, P, S) – rows = patients (same index as meta)\n",
    "def load_views() -> tuple[pd.DataFrame, pd.DataFrame, pd.DataFrame]:\n",
    "    C = pd.read_csv(\"/Users/harisreedeth/Desktop/D/personal/ProjectMAIP/data/01_processed/C_view.csv\")  # comorbidity\n",
    "    P = pd.read_csv(\"/Users/harisreedeth/Desktop/D/personal/ProjectMAIP/data/01_processed/P_view_scaled.csv\")  # physiology\n",
    "    S = pd.read_csv(\"/Users/harisreedeth/Desktop/D/personal/ProjectMAIP/data/01_processed/S_view.csv\")  # socio-contextual\n",
    "\n",
    "    # Make sure indices are the same and aligned\n",
    "    common_index = C.index.intersection(P.index).intersection(S.index)\n",
    "    C = C.loc[common_index]\n",
    "    P = P.loc[common_index]\n",
    "    S = S.loc[common_index]\n",
    "    return C, P, S\n",
    "\n",
    "# 3) Fused similarity (NxN) and SNF cluster labels\n",
    "def load_snf_results(common_ids: pd.Index) -> tuple[np.ndarray, np.ndarray]:\n",
    "    # W_fused: affinity/similarity matrix from your SNF-lite script\n",
    "    W_fused = np.load(\"W_fused.npy\")       # shape (N, N)\n",
    "    labels = np.load(\"snf_labels.npy\")     # shape (N,)\n",
    "\n",
    "    # Optionally reorder to match common_ids if needed\n",
    "    # If you saved them in the same order as meta / C/P/S, you can skip reindexing.\n",
    "    # Otherwise, you need a mapping from patient_id -> row index in W_fused.\n",
    "\n",
    "    assert W_fused.shape[0] == len(common_ids), \"W_fused rows != number of patients\"\n",
    "    assert labels.shape[0] == len(common_ids), \"labels length != number of patients\"\n",
    "    return W_fused, labels\n",
    "\n",
    "\n",
    "# =========================\n",
    "# 1. HELPER FUNCTIONS\n",
    "# =========================\n",
    "\n",
    "def minmax(x: np.ndarray) -> np.ndarray:\n",
    "    x = x.astype(float)\n",
    "    mn = np.nanmin(x)\n",
    "    mx = np.nanmax(x)\n",
    "    if mx <= mn:\n",
    "        return np.zeros_like(x, dtype=float)\n",
    "    return (x - mn) / (mx - mn)\n",
    "\n",
    "\n",
    "def make_embedding(W_fused: np.ndarray, n_components: int = 2) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Build a 2D embedding from the fused similarity matrix.\n",
    "    We use SpectralEmbedding with a precomputed affinity.\n",
    "    \"\"\"\n",
    "    emb = SpectralEmbedding(\n",
    "        n_components=n_components,\n",
    "        affinity=\"precomputed\",\n",
    "        random_state=42,\n",
    "    ).fit_transform(W_fused)\n",
    "    return emb  # shape (N, 2)\n",
    "\n",
    "\n",
    "def make_view_scores(C: pd.DataFrame, P: pd.DataFrame, S: pd.DataFrame) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Turn each view into a 0–1 \"burden\" score per patient.\n",
    "\n",
    "    Simple approach:\n",
    "    - C: number of comorbidities (row sum of binary indicators).\n",
    "    - P: mean of z-scored physiological variables (higher = worse).\n",
    "    - S: sum or mean of socio-contextual burden variables.\n",
    "\n",
    "    You can refine this later, but this gets you a sensible first cut.\n",
    "    \"\"\"\n",
    "    # --- C: comorbidity burden ---\n",
    "    # assume C columns are 0/1 or counts\n",
    "    c_raw = C.sum(axis=1).to_numpy()\n",
    "\n",
    "    # --- P: physiological burden ---\n",
    "    # z-score each column then row-mean\n",
    "    P_z = (P - P.mean()) / (P.std(ddof=0) + 1e-6)\n",
    "    p_raw = P_z.mean(axis=1).to_numpy()\n",
    "\n",
    "    # --- S: socio-context burden ---\n",
    "    # again, row sum or row mean depending on how you encoded it\n",
    "    s_raw = S.sum(axis=1).to_numpy()\n",
    "\n",
    "    c = minmax(c_raw)\n",
    "    p = minmax(p_raw)\n",
    "    s = minmax(s_raw)\n",
    "\n",
    "    view_profile = np.vstack([c, p, s]).T  # shape (N, 3)\n",
    "    return view_profile\n",
    "\n",
    "\n",
    "def make_primary_condition(C: pd.DataFrame) -> list[str]:\n",
    "    \"\"\"\n",
    "    Create a simple 'primaryCondition' label per patient.\n",
    "\n",
    "    Here: we pick the comorbidity column with the largest value for that patient.\n",
    "    You may want to replace this with something smarter (e.g. APACHE primary diagnosis).\n",
    "    \"\"\"\n",
    "    # If C is binary, argmax gives the first comorbidity present.\n",
    "    # If multiple are present, you just get the first; refine later if needed.\n",
    "    col_names = np.array(C.columns)\n",
    "    idx_max = C.values.argmax(axis=1)\n",
    "    primary = [col_names[j] for j in idx_max]\n",
    "    return primary\n",
    "\n",
    "\n",
    "def make_risk_score(meta: pd.DataFrame) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Build a 0–1 riskScore for the UI.\n",
    "\n",
    "    Options:\n",
    "    - use a predicted 1-year mortality probability if you have it,\n",
    "    - or rescale an existing severity score (SOFA, APS) to 0–1.\n",
    "    \"\"\"\n",
    "    if \"pred_mortality_1y\" in meta.columns:\n",
    "        raw = meta[\"pred_mortality_1y\"].to_numpy()\n",
    "    elif \"sofa\" in meta.columns:\n",
    "        raw = meta[\"sofa\"].to_numpy()\n",
    "    else:\n",
    "        # fallback: age-based proxy (just to get something on screen)\n",
    "        raw = meta[\"age\"].to_numpy()\n",
    "\n",
    "    return minmax(raw)\n",
    "\n",
    "\n",
    "# =========================\n",
    "# 2. MAIN: BUILD ARRAYS\n",
    "# =========================\n",
    "\n",
    "def build_app_data() -> dict:\n",
    "    # 1) Load metadata and views, align indices\n",
    "    meta = load_meta()\n",
    "    C, P, S = load_views()\n",
    "\n",
    "    # Ensure common index across meta and views\n",
    "    common_index = meta.index.intersection(C.index).intersection(P.index).intersection(S.index)\n",
    "    meta = meta.loc[common_index]\n",
    "    C = C.loc[common_index]\n",
    "    P = P.loc[common_index]\n",
    "    S = S.loc[common_index]\n",
    "\n",
    "    # 2) Load SNF fused matrix and labels in the same order\n",
    "    W_fused, labels = load_snf_results(common_index)\n",
    "    N = len(common_index)\n",
    "\n",
    "    # 3) Arrays we need\n",
    "    ids = common_index.astype(str).tolist()        # patient IDs as strings\n",
    "    clusters = labels.astype(int)                  # SNF cluster labels\n",
    "    embedding = make_embedding(W_fused, n_components=2)  # (N, 2)\n",
    "    view_profile = make_view_scores(C, P, S)              # (N, 3)\n",
    "\n",
    "    primary_condition = make_primary_condition(C)         # list[str]\n",
    "    age = meta[\"age\"].to_numpy().astype(int)              # age (or whatever your column is named)\n",
    "    # map sex to 'M'/'F'\n",
    "    if \"sex\" in meta.columns:\n",
    "        sex_raw = meta[\"sex\"]\n",
    "        # adapt mapping to your coding scheme\n",
    "        sex = np.where((sex_raw == 1) | (sex_raw == \"F\") | (sex_raw == \"Female\"), \"F\", \"M\")\n",
    "    else:\n",
    "        sex = np.array([\"M\"] * N)  # placeholder if you truly don't have sex (not ideal)\n",
    "\n",
    "    risk_score = make_risk_score(meta)                   # 0–1\n",
    "\n",
    "    # =========================\n",
    "    # 3. Build Patient objects\n",
    "    # =========================\n",
    "\n",
    "    patients = []\n",
    "    for i, pid in enumerate(ids):\n",
    "        patients.append({\n",
    "            \"id\": pid,\n",
    "            \"cluster\": int(clusters[i]),\n",
    "            \"embedding\": {\n",
    "                \"x\": float(embedding[i, 0]),\n",
    "                \"y\": float(embedding[i, 1]),\n",
    "            },\n",
    "            \"attributes\": {\n",
    "                \"age\": int(age[i]),\n",
    "                \"sex\": str(sex[i]),\n",
    "                \"riskScore\": float(risk_score[i]),\n",
    "                \"primaryCondition\": str(primary_condition[i]),\n",
    "            },\n",
    "            \"profile\": {\n",
    "                \"c\": float(view_profile[i, 0]),\n",
    "                \"p\": float(view_profile[i, 1]),\n",
    "                \"s\": float(view_profile[i, 2]),\n",
    "            },\n",
    "        })\n",
    "\n",
    "    # =========================\n",
    "    # 4. Build ClusterProfile\n",
    "    # =========================\n",
    "\n",
    "    unique_clusters = np.unique(clusters)\n",
    "    cluster_profiles = []\n",
    "    for k in unique_clusters:\n",
    "        mask = (clusters == k)\n",
    "        count = int(mask.sum())\n",
    "\n",
    "        if count == 0:\n",
    "            continue\n",
    "\n",
    "        # avg of view scores within cluster\n",
    "        avg_c = float(view_profile[mask, 0].mean())\n",
    "        avg_p = float(view_profile[mask, 1].mean())\n",
    "        avg_s = float(view_profile[mask, 2].mean())\n",
    "        avg_risk = float(risk_score[mask].mean())\n",
    "\n",
    "        # basic automatic label based on dominant view\n",
    "        max_val = max((\"c\", avg_c), (\"p\", avg_p), (\"s\", avg_s), key=lambda t: t[1])[0]\n",
    "        if max_val == \"c\":\n",
    "            name = f\"Cluster {k} – Chronic burden\"\n",
    "            description = \"Multimorbid, chronic-dominant profile.\"\n",
    "            dom_feats = [\"Diabetes\", \"CHF\", \"Polypharmacy\"]\n",
    "        elif max_val == \"p\":\n",
    "            name = f\"Cluster {k} – Acute physiology\"\n",
    "            description = \"Acute physiological instability.\"\n",
    "            dom_feats = [\"Tachycardia\", \"Hypoxia\", \"Elevated Lactate\"]\n",
    "        else:\n",
    "            name = f\"Cluster {k} – Context burden\"\n",
    "            description = \"High socio-economic deprivation.\"\n",
    "            dom_feats = [\"Housing instability\", \"Low income\", \"Social isolation\"]\n",
    "\n",
    "        cluster_profiles.append({\n",
    "            \"id\": int(k),\n",
    "            \"name\": name,\n",
    "            \"count\": count,\n",
    "            \"description\": description,\n",
    "            \"averages\": {\n",
    "                \"c\": avg_c,\n",
    "                \"p\": avg_p,\n",
    "                \"s\": avg_s,\n",
    "                \"risk\": avg_risk,\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89fb671a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "\n",
    "# Example placeholders – replace with your real arrays\n",
    "# ids: list[str], clusters: np.ndarray shape (n,)\n",
    "# embedding: np.ndarray shape (n,2)\n",
    "# view_profile: np.ndarray shape (n,3) columns = [c,p,s]\n",
    "# primary_condition, age, sex, risk_score: arrays or lists\n",
    "\n",
    "patients = []\n",
    "for i, pid in enumerate(ids):\n",
    "    patients.append({\n",
    "        \"id\": str(pid),\n",
    "        \"cluster\": int(clusters[i]),\n",
    "        \"embedding\": {\n",
    "            \"x\": float(embedding[i, 0]),\n",
    "            \"y\": float(embedding[i, 1]),\n",
    "        },\n",
    "        \"attributes\": {\n",
    "            \"age\": int(age[i]),\n",
    "            \"sex\": \"F\" if sex[i] == 1 else \"M\",  # adapt to your coding\n",
    "            \"riskScore\": float(risk_score[i]),\n",
    "            \"primaryCondition\": str(primary_condition[i]),\n",
    "        },\n",
    "        \"profile\": {\n",
    "            \"c\": float(view_profile[i, 0]),\n",
    "            \"p\": float(view_profile[i, 1]),\n",
    "            \"s\": float(view_profile[i, 2]),\n",
    "        },\n",
    "    })\n",
    "\n",
    "# Build clusters summary – align cluster IDs to your SNF labels\n",
    "clusters = []\n",
    "for k in sorted(set(clusters)):\n",
    "    mask = (clusters == k)\n",
    "    count = int(mask.sum())\n",
    "    if count == 0:\n",
    "        continue\n",
    "\n",
    "    avg_c = float(view_profile[mask, 0].mean())\n",
    "    avg_p = float(view_profile[mask, 1].mean())\n",
    "    avg_s = float(view_profile[mask, 2].mean())\n",
    "    avg_risk = float(risk_score[mask].mean())\n",
    "\n",
    "    # simple rule-based label, you can refine later\n",
    "    max_view = max((\"c\", avg_c), (\"p\", avg_p), (\"s\", avg_s), key=lambda t: t[1])[0]\n",
    "    if max_view == \"c\":\n",
    "        desc = \"Multimorbid, chronic-dominant profile.\"\n",
    "        dom_feats = [\"Diabetes\", \"CHF\", \"Polypharmacy\"]\n",
    "    elif max_view == \"p\":\n",
    "        desc = \"Acute physiological instability.\"\n",
    "        dom_feats = [\"Tachycardia\", \"Hypoxia\", \"Elevated Lactate\"]\n",
    "    else:\n",
    "        desc = \"High socio-economic deprivation.\"\n",
    "        dom_feats = [\"Housing instability\", \"Low income\", \"Social isolation\"]\n",
    "\n",
    "    clusters.append({\n",
    "        \"id\": int(k),\n",
    "        \"name\": f\"Phenotype {chr(65 + int(k))}\",\n",
    "        \"count\": count,\n",
    "        \"description\": desc,\n",
    "        \"averages\": {\"c\": avg_c, \"p\": avg_p, \"s\": avg_s, \"risk\": avg_risk},\n",
    "        \"dominantFeatures\": dom_feats,\n",
    "    })\n",
    "\n",
    "app_data = {\"patients\": patients, \"clusters\": clusters}\n",
    "\n",
    "with open(\"snf-data.json\", \"w\") as f:\n",
    "    json.dump(app_data, f, indent=2)\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
